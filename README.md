# Clustering Analysis of Knee Osteoarthritis Structural Progression Profiles
## Motivation and rationale  

### The Context:  
Osteoarthritis is a common condition that affects joints creating pain and difficulty in moving, in this I will be focusing on occurrences within the knee joint. It is caused by cartilage breaking down within the joints which can occur from injuries, family history and obesity [1]. Osteo is the most common form of arthritis affecting over 32.5 million adults in the US alone [2]. It is common in the older population because it occurs from usage and so increasing age means an increased risk of osteoarthritis. 

### The Problem:  
Many distinct patient subgroups are present within the osteoarthritis cohort and visualising them could further our understanding. With this further understanding we can realise cases where people may be more predisposed to osteoarthritis than initially expected. As well as this we can improve treatment plans to be more relevant to specific groups and narrow research areas. The main difficulty will be clustering the data from the progression profiles as there are many different algorithms all with different variations and parameter options. So, I will also have to measure the success of the clusters produced.

### My Approach:
For my project, I intend to analyse patient progression profiles from the knee osteoarthritis initiative cohort and find similarities in these profiles, showing distinct patient subgroups. To do this I will integrate the data and use a clustering algorithm to group data by the present similarities. These clusters will represent the distinct patient subgroups in the data. To make this information understandable I will produce visualisations of the findings. I aim to do this with the use of Python and its packages Pandas, Scikit-Learn and Seaborn. Which are for data analysis, clustering algorithms and visualisation respectively.

## Aim and objectives  
### Aim: Analyse data from patient progression profiles to find common subtypes of diseases and visualise the findings
### Objectives:
1)	Understand the data present in the progression profiles
Improving my understanding of what the data in these profiles represent will allow me to refine my research areas and ability to analyse the data. I will complete this objective before I begin to integrate the data as otherwise, mistakes will likely occur.  
2)	Integrate the data from progression profiles
Combining all of the data from the profiles means I can begin implementing clustering algorithms. Also, It will give me a new view of the data from which allows me to draw conclusions and predictions of what the clusters may resemble, enabling me to make informed decisions when assessing the clusters.  
3)	Explore different clustering algorithms that can be used with the data
These algorithms will group similar data showing common occurrences between the progression profiles and trends. I will visualise these clusters because the algorithms have various parameters each affecting the clusters produced and in turn the provided view, and I will evaluate them using metrics built-in to Scikit-Learn.  
4)	Group common similarities between profiles using the optimal clustering algorithm
I will discover the optimal clustering algorithm using metrics built-in to Scikit-Learn [3]. For example, using “Silhouette Coefficient” which produces a numerical score representing the distance between clusters, where the aim is to achieve a high score. I will be using three separate metrics, which will allow me to assess the clustering algorithms and tune them as necessary.  
5)	Visualise similarities in an informative manner using the clusters produced
With the data being clustered I can begin to conclude the groupings by producing visualisations of the data. These visualisations should show distinct patient subgroups.

## Background Research
| Source                                            | Description | Relevance |
|---------------------------------------------------|-------------|----------------------------------------------------------------------------|
| Osteoarthritis: toward a comprehensive understanding of pathological mechanism [4] | This paper provides a lot of background information on Osteoarthritis, including Its effects and causes. It outlines areas such as the progression of the disease as being poorly understood. As a result of the lack of understanding, there’s no method to deaccelerate the progression of the disease.| Reading the paper conveys the seriousness of the disease and further solidifies how common it is. Learning about the disease will greatly affect my work as well as my effectiveness in understanding and analysing the data. This paper also shows the need for further research on this topic. |
| Patients with knee osteoarthritis can be divided into subgroups [5] | This article shows an example where the osteoarthritis cohort can be divided into subgroups using a clustering algorithm. These subgroups showed the patients could be divided by specific clinical characteristics and how these findings can further the understanding of development, potentially inspiring improved treatment strategies. | This shows an example where clustering knee osteoarthritis cohort data can be used to further our understanding of the disease and highlight distinct groups. Furthermore, Python was used to produce clustering with K-means, the article explains how they implemented the algorithm, including the number of repetitions and how they found the number of subgroups to use. I am intending to use K-means so this methodology is very useful to learn about. |
| Distinct subtypes of knee osteoarthritis: data from the Osteoarthritis Initiative [6] | This shows how the osteoarthritis initiative cohort is a collection of distinct subtypes of osteoarthritis through the use of clustering analysis. The clusters showed that different causes can lead to different types of knee osteoarthritis. | Reading this furthered my understanding of the disease, showing how clusters can be used in comparison with data to draw further conclusions. It also mentions various methods that can be used including K-means, which I intend to use, and other methods such as LCA.  |
| Types of Clustering Algorithms [7] | This discusses four types of clustering algorithms that can be used, all of which contain their own variants but the focus will be on these types included. Each variant produces very different visuals of clusters showing how different they are and the need to explore different types rather than variants. | Clustering will be a big part of the project, I will produce many variations of clusters using clustering algorithms all with various parameters. These are the most common algorithms and will be the focus of my experiments in clustering.  I am intending to use a few clustering types which are explored in this article, one of which is Density-Based clustering. This type is good in this scenario because the data does not have high dimensions and this algorithm does not assign outliers to clusters, which will prevent visualisations from being misleading. I can implement this type of algorithm with Scikit-learn in two ways which are through DBSCAN and OPTICS, both produce very similar results but the latter produces a reachability graph. This graph could be useful in assessing the effectiveness of the algorithm and also further my understanding of the results. |
| Clustering Algorithms: A Comparative Approach [8]  | This paper gives background information to clustering algorithms and assesses how common types perform. It shows how performance can vary between the types of data tested and the parameters of each algorithm type. It makes three assessments for each type tested, which are using the default parameters and single or random parameter changes. | I need to assess various types of clustering algorithms all with their own parameters, this provides ideas on how to vary the parameters for testing the algorithms quickly and uniformly. It also outlines some common clustering methods and gives some explanations about how they work and what their parameters represent. One of the algorithms outlined in this article is hierarchical clustering which I am intending to use. It found this type performed well on smaller datasets, was the fastest tested and had limited performance on larger datasets. There are also two variations which are agglomerative and divisive which are top-down and bottom-up approaches for the clusters, meaning the hierarchy will either start or end with a unique cluster. |
| What Makes a Visualization Memorable [9] | This discusses the importance of visualisations and how they can be easily insufficient in conveying their meaning. It shows measurements of memorability for various visualizations, showing how effective they are. | I will have to visualise my findings and clusters in a meaningful way, in which I mean one where the data can be easily understood. Each of the clustering algorithms will produce different visuals so I need to ensure that when presenting these findings, they stand out from one another. |

## Work plan  
### Done so far:
Firstly, I have done background research on a few of the topics I will be encountering throughout. The main one is	based around clustering algorithms, these will be a big part of the project represented in objectives 3 and 4. I have read an article from Google Developers [6], which summarised some of the common types and visualised example results. From this article I concluded a distribution-based algorithm such as DBSCAN or OPTICS would be a good choice, which can be done with Scikit-Learn.

Furthermore, I have looked at a paper discussing the performances of different types [7], which gave some in-depth comparisons and experiments of common clustering algorithms. This solidified some of my understanding produced from the prior article, as well as explaining some of the workings of the algorithms and their parameters. As a result, I am confident in the usage of Hierarchal clustering and I will do some brief testing between divisive and agglomerative clustering.

I will be using Scikit-Learn to implement the algorithms because this package enables me to implement the mentioned clustering algorithms and useful metrics to assess the clusters. I will also be using Pandas and Seaborn as I have experience with both and they are well suited to the task, Pandas will be used for processing the data and preparing it for implementing the algorithms and Seaborn will be used for visualisations, I chose this package because it is designed around Pandas.

### Future Plans:
To start with I will solidify my understanding of the data. This will be crucial for the next steps because if I lack this understanding, I will be very prone to making mistakes which will delay my progress. Following this I will begin to integrate the data, which produces a new view of the data enabling me to draw some initial conclusions.

At this point I will begin implementing the clustering algorithms and I will evaluate the following types: K-means, Density-Based and Hierarchal. I will repeat each experiment although this number is not yet known as I will not know how long they will take until I have begun this phase. I will have to evaluate each algorithm with different parameter configurations. I intend to perform parameter sweeps for each of the algorithm types to find the optimal configuration. I will know if configurations are appropriate because the results will be stable and be similar to past results from other algorithm types. Each of these configurations will be evaluated with Silhouette Coefficient, Calinski-Harabasz Index and Davies-Bouldin Index. I will be using these metrics because they do not require the ground truth to be known. However, I will have to be aware each of these metrics tends to score higher for Density-Based cluster.

Finally, I will produce high-quality visualisations of the final clusters, these visualisations will show which distinct patient subgroups exist within the Osteoarthritis Initiative cohort. This is important as I will likely have to produce multiple versions of the visualisations to ensure they are informative.

### Risks and Mitigation
Each phase of the work is dependent on one another as shown in the Gantt chart, meaning if I fall behind on one task, I lose time to complete all those that follow. The main risk comes from the clustering algorithm tasks, this is because I will be performing many experiments but I will not know how long they will take until beginning them. However, I should be able to recover from these delays as weekends are unplanned times. Furthermore, experiments should become easier to set up as I progress through the phase and so I will be actively gaining time. Although if this issue does occur and I do not believe I will be able to make up for the lost time I can simply reduce the number of experiments.

## References  
[1] NHS (2019). Overview - Osteoarthritis. NHS. Available at: https://www.nhs.uk/conditions/osteoarthritis/.  
[2] CDC (2020). Osteoarthritis (OA).  Centers for Disease Control and Prevention. Available at: https://www.cdc.gov/arthritis/basics/osteoarthritis.htm.   
[3] Scikit-Learn.org. (2010). 2.3. Clustering — Scikit-Learn 0.20.3 documentation.  Available at: https://Scikit-Learn.org/stable/modules/clustering.html.   
[4] Chen, D., Shen, J., Zhao, W., Wang, T., Han, L., Hamilton, J.L. and Im, H.-J. (2017). Osteoarthritis: toward a comprehensive understanding of pathological mechanism. Bone Research. Available at: https://doi.org/10.1038/boneres.2016.44   
[5] Petersen E.T., Rytter S., Koppens D., Dalsgaard J., Hansen T.B., Larsen N.E., Andersen M.S. and Stilling M. (2022). Patients with knee osteoarthritis can be divided into subgroups based on tibiofemoral joint kinematics of gait. Available at: https://doi.org/10.1016/j.joca.2021.10.011.   
[6] Waarsing, J.H., Bierma-Zeinstra, S.M.A. and Weinans, H. (2015). Distinct subtypes of knee osteoarthritis: data from the Osteoarthritis Initiative. Available at: https://doi.org/10.1093/rheumatology/kev100   
[7] Google Developers. (2015). Clustering Algorithms | Clustering in Machine Learning. Available at: https://developers.google.com/machine-learning/clustering/clustering-algorithms.   
[8] Rodriguez, M.Z., Comin, C.H., Casanova, D., Bruno, O.M., Amancio, D.R., Costa, L. da F. and Rodrigues, F.A. (2019). Clustering algorithms: A comparative approach. Available at: https://doi.org/10.1371/journal.pone.0210236  
[9] Borkin, M.A., Vo, A.A., Bylinskii, Z., Isola, P., Sunkavalli, S., Oliva, A. and Pfister, H. (2013). What Makes a Visualization Memorable? IEEE Transactions on Visualization and Computer Graphics. Available at https://doi.org/10.1109/TVCG.2013.234  
